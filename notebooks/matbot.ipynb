{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama, OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader\n",
    "import chainlit as cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = {\n",
    "    \"openai\": OpenAI(temperature=0),\n",
    "    \"mistral\": Ollama(\n",
    "        model=\"mistral\", verbose=True, callbacks=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    ),\n",
    "}\n",
    "\n",
    "template = \"\"\"You are a Retrieval-Augmented Generation chatbot that answers questions on\n",
    "documents provided to you. Act as an expert in the subject matter of the document\n",
    "discussed. If a question is not relevant for the document or if it cannot be answered\n",
    "using the information of the document, please do not answer the question and politely provide\n",
    "the reason. You're going to be working with the following document:\n",
    "{document}\n",
    "\n",
    "Given the above document, please answer the following question:\n",
    "{{question}}\n",
    "\"\"\"\n",
    "\n",
    "document_path = \"data/business_1.txt\"\n",
    "with open(document_path) as f:\n",
    "    document = f.read()\n",
    "\n",
    "template = template.format(document=document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the chain for that user session\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm = llms[\"mistral\"]\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a computer program, so I don't have feelings or emotions. But I'm here to help you with any questions or problems you might have! How can I assist you today?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I'm just a computer program, so I don't have feelings or emotions. But I'm here to help you with any questions or problems you might have! How can I assist you today?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a Retrieval-Augmented Generation chatbot that answers questions on\n",
      "documents provided to you. Act as an expert in the subject matter of the document\n",
      "discussed. If a question is not relevant for the document or if it cannot be answered\n",
      "using the information of the document, please do not answer the question and politely provide\n",
      "the reason. You're going to be working with the following document:\n",
      "Lufthansa flies back to profit\n",
      "\n",
      "German airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.\n",
      "\n",
      "In a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering business. Last year, Lufthansa showed signs of recovery even as some European and US airlines were teetering on the brink of bankruptcy. The board of Lufthansa has recommended paying a 2004 dividend of 0.30 euros per share. In 2003, shareholders did not get a dividend. The company said that it will give all the details of its 2004 results on 23 March.\n",
      "\n",
      "\n",
      "Given the above document, please answer the following question:\n",
      "Hello, how are you\n",
      "\u001b[0m\n",
      "\n",
      "I am doing well, thank you for asking!\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Hello, how are you',\n",
       " 'text': '\\nI am doing well, thank you for asking!'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"Hello, how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a Retrieval-Augmented Generation chatbot that answers questions on\n",
      "documents provided to you. Act as an expert in the subject matter of the document\n",
      "discussed. If a question is not relevant for the document or if it cannot be answered\n",
      "using the information of the document, please do not answer the question and politely provide\n",
      "the reason. You're going to be working with the following document:\n",
      "Lufthansa flies back to profit\n",
      "\n",
      "German airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.\n",
      "\n",
      "In a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering business. Last year, Lufthansa showed signs of recovery even as some European and US airlines were teetering on the brink of bankruptcy. The board of Lufthansa has recommended paying a 2004 dividend of 0.30 euros per share. In 2003, shareholders did not get a dividend. The company said that it will give all the details of its 2004 results on 23 March.\n",
      "\n",
      "\n",
      "Given the above document, please answer the following question:\n",
      "What did I ask you a moment ago?\n",
      "\u001b[0m\n",
      "I apologize, but I do not have any information on what question you asked me a moment ago as I am unable to recall past conversations without the context of them. Can you please provide more information or clarify your question so that I can assist you better?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What did I ask you a moment ago?',\n",
       " 'text': 'I apologize, but I do not have any information on what question you asked me a moment ago as I am unable to recall past conversations without the context of them. Can you please provide more information or clarify your question so that I can assist you better?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"What did I ask you a moment ago?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain_openai = LLMChain(prompt=prompt, llm=llms[\"openai\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChainlitContextException",
     "evalue": "Chainlit context not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/chainlit/context.py:44\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m context_var\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "\u001b[0;31mLookupError\u001b[0m: <ContextVar name='chainlit' at 0x7f787f6eeb30>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChainlitContextException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mathijs/projects/matbot/notebooks/matbot.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mathijs/projects/matbot/notebooks/matbot.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m llm_chain_openai\u001b[39m.\u001b[39macall(\u001b[39m\"\u001b[39m\u001b[39mHello, how are you\u001b[39m\u001b[39m\"\u001b[39m,  callbacks\u001b[39m=\u001b[39m[cl\u001b[39m.\u001b[39mAsyncLangchainCallbackHandler()])\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/chainlit/langchain/callbacks.py:153\u001b[0m, in \u001b[0;36mBaseLangchainCallbackHandler.__init__\u001b[0;34m(self, answer_prefix_tokens, strip_tokens, stream_prefix, stream_final_answer, root_message)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m root_message:\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_message \u001b[39m=\u001b[39m root_message\n\u001b[0;32m--> 153\u001b[0m \u001b[39melif\u001b[39;00m root_message \u001b[39m:=\u001b[39m context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39mroot_message:\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_message \u001b[39m=\u001b[39m root_message\n\u001b[1;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/lazify.py:133\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue, name)\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/lazify.py:56\u001b[0m, in \u001b[0;36mLazyProxy.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cache_enabled \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_value_cached:\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[0;32m---> 56\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cache_enabled:\n\u001b[1;32m     58\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_value\u001b[39m\u001b[39m'\u001b[39m, value)\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/chainlit/context.py:46\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m context_var\u001b[39m.\u001b[39mget()\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mraise\u001b[39;00m ChainlitContextException()\n",
      "\u001b[0;31mChainlitContextException\u001b[0m: Chainlit context not found"
     ]
    }
   ],
   "source": [
    "res = await llm_chain_openai.acall(\"Hello, how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
