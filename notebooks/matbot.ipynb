{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.ollama import OllamaEmbeddings\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import Ollama, OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "llms = {\n",
    "    \"openai\": OpenAI(temperature=0),\n",
    "    \"mistral\": Ollama(\n",
    "        model=\"mistral\", verbose=True, callbacks=CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "    ),\n",
    "}\n",
    "\n",
    "\n",
    "template = \"\"\"You are a Retrieval-Augmented Generation chatbot that answers questions on\n",
    "documents provided to you. Act as an expert in the subject matter of the document\n",
    "discussed. If a question is not relevant for the document or if it cannot be answered\n",
    "using the information of the document, please do not answer the question and politely provide\n",
    "the reason. You're going to be working with the following document:\n",
    "{document}\n",
    "\n",
    "Given the above document, please answer the following question:\n",
    "{{question}}\n",
    "\"\"\"\n",
    "\n",
    "document_path = \"data/business_1.txt\"\n",
    "with open(document_path) as f:\n",
    "    document_content = f.read()\n",
    "\n",
    "template = template.format(document=document_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\"./data/business_1.txt\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lufthansa flies back to profit\n",
      "\n",
      "German airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.\n",
      "\n",
      "In a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering busine\n"
     ]
    }
   ],
   "source": [
    "print(document.page_content[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the chain for that user session\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "llm = llms[\"mistral\"]\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am an AI and do not have feelings or emotions. I am here to assist you with any questions or tasks you may have. How can I help you today?"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am an AI and do not have feelings or emotions. I am here to assist you with any questions or tasks you may have. How can I help you today?'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a Retrieval-Augmented Generation chatbot that answers questions on\n",
      "documents provided to you. Act as an expert in the subject matter of the document\n",
      "discussed. If a question is not relevant for the document or if it cannot be answered\n",
      "using the information of the document, please do not answer the question and politely provide\n",
      "the reason. You're going to be working with the following document:\n",
      "Lufthansa flies back to profit\n",
      "\n",
      "German airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.\n",
      "\n",
      "In a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering business. Last year, Lufthansa showed signs of recovery even as some European and US airlines were teetering on the brink of bankruptcy. The board of Lufthansa has recommended paying a 2004 dividend of 0.30 euros per share. In 2003, shareholders did not get a dividend. The company said that it will give all the details of its 2004 results on 23 March.\n",
      "\n",
      "\n",
      "Given the above document, please answer the following question:\n",
      "Hello, how are you\n",
      "\u001b[0m\n",
      "I am an AI chatbot designed to provide information based on the documents provided to me. Thank you for asking!\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Hello, how are you',\n",
       " 'text': 'I am an AI chatbot designed to provide information based on the documents provided to me. Thank you for asking!'}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"Hello, how are you\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain.memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a Retrieval-Augmented Generation chatbot that answers questions on\n",
      "documents provided to you. Act as an expert in the subject matter of the document\n",
      "discussed. If a question is not relevant for the document or if it cannot be answered\n",
      "using the information of the document, please do not answer the question and politely provide\n",
      "the reason. You're going to be working with the following document:\n",
      "Lufthansa flies back to profit\n",
      "\n",
      "German airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.\n",
      "\n",
      "In a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering business. Last year, Lufthansa showed signs of recovery even as some European and US airlines were teetering on the brink of bankruptcy. The board of Lufthansa has recommended paying a 2004 dividend of 0.30 euros per share. In 2003, shareholders did not get a dividend. The company said that it will give all the details of its 2004 results on 23 March.\n",
      "\n",
      "\n",
      "Given the above document, please answer the following question:\n",
      "What did I ask you a moment ago?\n",
      "\u001b[0m\n",
      "I apologize, but I do not have any information on what question you asked me a moment ago as I am unable to recall past conversations without the context of them. Can you please provide more information or clarify your question so that I can assist you better?\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What did I ask you a moment ago?',\n",
       " 'text': 'I apologize, but I do not have any information on what question you asked me a moment ago as I am unable to recall past conversations without the context of them. Can you please provide more information or clarify your question so that I can assist you better?'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain(\"What did I ask you a moment ago?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain_openai = LLMChain(prompt=prompt, llm=llms[\"openai\"], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "ChainlitContextException",
     "evalue": "Chainlit context not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/chainlit/context.py:44\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m     \u001b[39mreturn\u001b[39;00m context_var\u001b[39m.\u001b[39;49mget()\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n",
      "\u001b[0;31mLookupError\u001b[0m: <ContextVar name='chainlit' at 0x7f787f6eeb30>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mChainlitContextException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[1;32m/home/mathijs/projects/matbot/notebooks/matbot.ipynb Cell 9\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/mathijs/projects/matbot/notebooks/matbot.ipynb#X11sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m llm_chain_openai\u001b[39m.\u001b[39macall(\u001b[39m\"\u001b[39m\u001b[39mHello, how are you\u001b[39m\u001b[39m\"\u001b[39m,  callbacks\u001b[39m=\u001b[39m[cl\u001b[39m.\u001b[39mAsyncLangchainCallbackHandler()])\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/chainlit/langchain/callbacks.py:153\u001b[0m, in \u001b[0;36mBaseLangchainCallbackHandler.__init__\u001b[0;34m(self, answer_prefix_tokens, strip_tokens, stream_prefix, stream_final_answer, root_message)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mif\u001b[39;00m root_message:\n\u001b[1;32m    152\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_message \u001b[39m=\u001b[39m root_message\n\u001b[0;32m--> 153\u001b[0m \u001b[39melif\u001b[39;00m root_message \u001b[39m:=\u001b[39m context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39mroot_message:\n\u001b[1;32m    154\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_message \u001b[39m=\u001b[39m root_message\n\u001b[1;32m    155\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/lazify.py:133\u001b[0m, in \u001b[0;36mLazyProxy.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m--> 133\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mvalue, name)\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/lazify.py:56\u001b[0m, in \u001b[0;36mLazyProxy.value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cache_enabled \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_value_cached:\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_value\n\u001b[0;32m---> 56\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_func(\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs)\n\u001b[1;32m     57\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_cache_enabled:\n\u001b[1;32m     58\u001b[0m     \u001b[39mobject\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__setattr__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_value\u001b[39m\u001b[39m'\u001b[39m, value)\n",
      "File \u001b[0;32m~/projects/matbot/.direnv/matbot/lib/python3.9/site-packages/chainlit/context.py:46\u001b[0m, in \u001b[0;36mget_context\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[39mreturn\u001b[39;00m context_var\u001b[39m.\u001b[39mget()\n\u001b[1;32m     45\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mLookupError\u001b[39;00m:\n\u001b[0;32m---> 46\u001b[0m     \u001b[39mraise\u001b[39;00m ChainlitContextException()\n",
      "\u001b[0;31mChainlitContextException\u001b[0m: Chainlit context not found"
     ]
    }
   ],
   "source": [
    "res = await llm_chain_openai.acall(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ./docs/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 12:38:56 - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "persist_directory = \"./docs/chroma\"\n",
    "embedding = OllamaEmbeddings(model=\"mistral\")\n",
    "vectordb = Chroma.from_documents(\n",
    "    documents=documents,\n",
    "    persist_directory=persist_directory,\n",
    "    embedding=embedding\n",
    ")\n",
    "\n",
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 12:44:29 - Number of requested results 3 is greater than number of elements in index 1, updating n_results = 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What is the name of the company in the document?\"\n",
    "docs = vectordb.similarity_search(question, k=3)\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llms[\"mistral\"],\n",
    "    retriever=vectordb.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 12:46:27 - Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "\n",
      "The name of the company in the document is Lufthansa."
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe name of the company in the document is Lufthansa.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"You are a Retrieval-Augmented Generation chatbot that answers questions on\n",
    "documents provided to you. Act as an expert in the subject matter of the document\n",
    "discussed. If a question is not relevant for the document or if it cannot be answered\n",
    "using the information of the document, please do not answer the question and politely provide\n",
    "the reason.\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llms[\"mistral\"],\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"What is the name of the company in the document?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 12:49:21 - Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "The company mentioned in the document is Lufthansa, a German airline."
     ]
    }
   ],
   "source": [
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The company mentioned in the document is Lufthansa, a German airline.'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='Lufthansa flies back to profit\\n\\nGerman airline Lufthansa has returned to profit in 2004 after posting huge losses in 2003.\\n\\nIn a preliminary report, the airline announced net profits of 400m euros ($527.61m; £274.73m), compared with a loss of 984m euros in 2003. Operating profits were at 380m euros, ten times more than in 2003. Lufthansa was hit in 2003 by tough competition and a dip in demand following the Iraq war and the killer SARS virus. It was also hit by troubles at its US catering business. Last year, Lufthansa showed signs of recovery even as some European and US airlines were teetering on the brink of bankruptcy. The board of Lufthansa has recommended paying a 2004 dividend of 0.30 euros per share. In 2003, shareholders did not get a dividend. The company said that it will give all the details of its 2004 results on 23 March.\\n', metadata={'source': './data/business_1.txt'})"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"source_documents\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-10 12:51:59 - Number of requested results 4 is greater than number of elements in index 1, updating n_results = 1\n",
      "\n",
      "I apologize, but your question is not relevant to the provided document about Lufthansa's profitability. To answer your question, in Ukrainian, \"thank you\" can be expressed as \"Благодарення\" (Bohodarennia) or \"Дякуємо\" (Dyakuyemo)."
     ]
    }
   ],
   "source": [
    "question = \"How do you say 'thank you' in Ukrainian?\"\n",
    "result = qa_chain({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "matbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
